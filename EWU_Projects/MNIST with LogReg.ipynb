{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Predicting Hand-Written Digits\n",
    "Machine Learning\n",
    "\n",
    "Richard Teller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the hand written digit images from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now display one of the sample digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f416d77c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f416d77c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[3]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the predictor from the response data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC6++f6S2aN2DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f416deb6748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the image.\n",
    "# turn the data into a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the data into training and testing groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (1437,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = digits.data[:, :64]\n",
    "Y = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Logistic Regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(solver = 'lbfgs') # create a LogReg model object\n",
    "\n",
    "model.fit(X_train, y_train) # fit the model to our data\n",
    "\n",
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[42  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 34  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 35  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  0  0  0  1  1]\n",
      " [ 0  0  0  0 38  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 29  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 37  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 36  0  1]\n",
      " [ 0  0  0  0  0  1  0  0 27  1]\n",
      " [ 0  0  0  0  0  1  0  0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "print('Confusion matrix')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        43\n",
      "          1       1.00      0.97      0.99        35\n",
      "          2       1.00      0.97      0.99        36\n",
      "          3       0.95      0.95      0.95        41\n",
      "          4       0.97      1.00      0.99        38\n",
      "          5       0.94      0.97      0.95        30\n",
      "          6       1.00      1.00      1.00        37\n",
      "          7       1.00      0.97      0.99        37\n",
      "          8       0.90      0.93      0.92        29\n",
      "          9       0.91      0.94      0.93        34\n",
      "\n",
      "avg / total       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "**Which digits are most often confused by the model?**\n",
    "\n",
    "The digit most often confused would be where there are a lot of numbers in each column for a single row.  This would mean for that particular digit (the row) the model thought it was many different numbers (the columns).  In our model we see it did a pretty good job of predicting the digits because there are very few numbers that are placed not on the diagonal.  By looking at the confusion matrix we see the digits 3, 8, and 9 are confused the most (each predicted 2 wrong digits).  However if the matrix was a lot messier we may want to do something like this to display the most confused digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit followed by Incorrect Predictions\n",
      "0: 1\n",
      "1: 1\n",
      "2: 1\n",
      "3: 2\n",
      "4: 0\n",
      "5: 1\n",
      "6: 0\n",
      "7: 1\n",
      "8: 2\n",
      "9: 2\n"
     ]
    }
   ],
   "source": [
    "# To find the total number of incorrect predictions for each digit we can sum the values in the row\n",
    "# and then subtract the diagonal entry for that row (since the diagonal value were the correct predictions)\n",
    "\n",
    "print(\"Digit followed by Incorrect Predictions\")\n",
    "i = 0\n",
    "while i < 10:\n",
    "    badPredictions = confusion[i].sum() - confusion.diagonal()[i]\n",
    "    print(\"%d: %d\" % (i, badPredictions))\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus again, we see digits 3, 8, and 9 have the most incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the accuracy of the model?**\n",
    "\n",
    "The accuracy is (how many predicted correctly) / (how many total tested).  We can find how many were predicted correctly by summing the diagonal with the following code ``` confusion.diagonal().sum()``` and we can find the total tested with ```y_test.shape```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n",
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "print(confusion.diagonal().sum())\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have 349/360 = 0.96945 (Notice 360 is also the final entry in the support column in the table above and accuracy would be the final entry in the precision column).\n",
    "\n",
    "**Which digits are most often recognized correctly?**\n",
    "\n",
    "The digits with a perfect score of being predicted 100% of the time are digits 4 and 6.  They only have a number in their diagonal and 0's everywhere else in the row.  Having only a number in the diagonal is saying, everytime we had the digit 4, we predicted 4, for example.  The number itself is telling us how many times we made that correct prediction. Notice digits 4 and 6 have 0 bad predictions in my print out.\n",
    "\n",
    "**Which are recognized incorrectly?**\n",
    "\n",
    "Any number that is not on the diagonal indicates an incorrect prediction.  So for example in the first row we see a 1 in the fifth column.  This is saying that we had the digit 0 (because we're in the first row), but the model predicted a 4 (because fifth column).  And also in the next row, which represents the digit 1, we see we had a 1 in the second to last column which tells us that we had the digit 1 but we predicted an 8.  Again, anywhere there is a number that is not on the diagonal represents an incorrect prediction.  The number itself tells us how many times we made that incorrect prediction (how many 1's we thought were 7's, for example)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
